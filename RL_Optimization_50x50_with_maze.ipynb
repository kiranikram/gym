{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL Optimization_50x50 with maze.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiranikram/gym/blob/master/RL_Optimization_50x50_with_maze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB4tBWIdXP0A",
        "colab_type": "code",
        "outputId": "5ffd78ad-a688-48d6-8b8d-ffe97dfe557c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0WnuUDTXQ2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/custom_gym/Nyc_maze/custom_env_dir/envs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZdo89tiLiOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib.pyplot as plt\n",
        "from abc import ABC\n",
        "from abc import abstractmethod\n",
        "#from gym_pull.envs.registration import registry, register, make, spec\n",
        "import numpy as np\n",
        "from gym.utils import seeding\n",
        "from PIL import Image\n",
        "from skimage.draw import rectangle\n",
        "from collections import namedtuple\n",
        "from custom_env import NycMaze1\n",
        "import sys\n",
        "from contextlib import closing\n",
        "from six import StringIO\n",
        "from gym import utils\n",
        "from gym.envs.toy_text import discrete\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import display\n",
        "from time import sleep\n",
        "import matplotlib.image as image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYmQlKkZKrle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Actions = {'North': 0, 'South': 1, 'East': 2, 'West': 3}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIyD1fcZ1ehd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gym import Env, spaces\n",
        "from gym.utils import seeding\n",
        "class environment(Env):\n",
        "  def __init__(self, nS, nA, P, isd, start_state):\n",
        "    # nS = number of States\n",
        "    # na = Number of actions\n",
        "    # P = transitions \n",
        "    # isd = initial state distribution \n",
        "    self.start_state = start_state\n",
        "    self.s = start_state #change tis later to random 🤔\n",
        "    self.P = P\n",
        "    self.isd = isd\n",
        "    self.lastaction = None\n",
        "    self.nS = nS\n",
        "    self.nA = nA\n",
        "\n",
        "    self.action_space = spaces.Discrete(self.nA)\n",
        "    self.observation_space = spaces.Discrete(self.nS)\n",
        "    self.seed()\n",
        "\n",
        "  def seed(self, seed=None):\n",
        "    self.np_random, seed = seeding.np_random(seed)\n",
        "    return [seed]\n",
        "\n",
        "  def reset(self):\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def step(self, a):\n",
        "    raise NotImplementedError\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1SA7ub10xe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class driver(environment):\n",
        "  def __init__(self, **kwargs):\n",
        "    self.start = np.array([2,2])\n",
        "    self.maze = None\n",
        "\n",
        "    self.start = kwargs['start_car']\n",
        "    self.goal = kwargs['destination']\n",
        "    self.width = kwargs['block_width']\n",
        "    self.height = kwargs['block_height']\n",
        "    self.blocks = kwargs['blocks']\n",
        "    self.obstacle_width = kwargs['obstacle_width']\n",
        "    self.obstacle_height = kwargs['obstacle_height']\n",
        "\n",
        "    self.maze = self.build_maze(self.width,self.height, self.obstacle_width, self.obstacle_height, self.blocks)\n",
        "    self.set_start(self.start)\n",
        "    self.state = self.encode_state(self.start[0], self.start[1])\n",
        "    self.set_goal(self.goal)\n",
        "    self.trafic_R = None\n",
        "\n",
        "    num_states = self.width*self.height \n",
        "    self.observation_space = num_states\n",
        "    print(\"num_states\", num_states)\n",
        "    \n",
        "    num_actions = 4 #\"(N,S,E,W)\"\n",
        "    self.action_space = num_actions\n",
        "    \n",
        "    num_rows = self.width\n",
        "    num_col = self.height\n",
        "    max_rows = num_rows - 1\n",
        "    max_col = num_col - 1\n",
        "\n",
        "    self.R = {state: {action: [] for action in range(num_actions)} for state in range(num_states+1)}\n",
        "\n",
        "    initial_state_distribution = np.zeros(num_states)\n",
        "    \n",
        "    for row in range(num_rows):\n",
        "      for col in range(num_col):\n",
        "        state = self.encode_state(row,col)\n",
        "        if (row,col) != self.goal:\n",
        "          initial_state_distribution[state] += 1 #why is this necessary?\n",
        "        for action in range(num_actions):\n",
        "          new_row, new_col = row, col \n",
        "          done = False\n",
        "          reward = -1\n",
        "          car_loc = (row,col)\n",
        "          \n",
        "          #Actions = {'North': 0, 'South': 1, 'East': 2, 'West': 3}\n",
        "          if action == 0:\n",
        "            new_row = max(row - 1, 0)\n",
        "          elif action == 1:\n",
        "            new_row = min(row + 1, max_rows)\n",
        "          elif action == 2:\n",
        "            new_col = min(col + 1, max_col)\n",
        "          elif action == 3:\n",
        "            new_col = max(col - 1, 0)\n",
        "\n",
        "          if (new_row,new_col) == self.goal:\n",
        "            done = True\n",
        "            reward = 100\n",
        "          elif self.maze[new_row, new_col] == 1:\n",
        "            reward = -50 # this is a crash 🚒🚑\n",
        "\n",
        "          new_state = self.encode_state(new_row,new_col)\n",
        "          self.R[state][action].append([1,new_state,reward,done])\n",
        "    \n",
        "    initial_state_distribution /= initial_state_distribution.sum()\n",
        "    environment.__init__(self, num_states, num_actions, self.R, initial_state_distribution, self.start) \n",
        "\n",
        "  def build_maze(self,width, height, obstacle_width, obstacle_height, blocks):\n",
        "    x = np.ones([height, width], dtype=np.uint8)\n",
        "    start = (2,2)\n",
        "    end = (height-3,width -3)\n",
        "    rr, cc = rectangle(start, end, shape = x.shape)\n",
        "    x[rr, cc] = 1\n",
        "    #print(width // blocks)\n",
        "    \n",
        "    for i in range(0,width-1,(width//blocks)):\n",
        "      x[:,i] = 0\n",
        "    for i in range(0,height-1,(height//blocks)):\n",
        "      x[i,:] = 0\n",
        "    \n",
        "    x[1, :] = 0\n",
        "    x[-2, :] = 0\n",
        "    x[:, 1] = 0\n",
        "    x[:, -2] = 0\n",
        "    \n",
        "    #builds the walls\n",
        "    x[0, :] = 1\n",
        "    x[-1, :] = 1\n",
        "    x[:, 0] = 1\n",
        "    x[:, -1] = 1\n",
        "    return x\n",
        "\n",
        "  def encode_state(self,row, column):\n",
        "    #if multiple locations then encode needs to be adapted\n",
        "    i = row\n",
        "    i *= self.height\n",
        "    i += column\n",
        "    return i \n",
        "\n",
        "  def decode_state(self, state):\n",
        "    # out = [row,column]\n",
        "    out = []\n",
        "    out.append(state % self.width)\n",
        "    state = state // self.width\n",
        "    out.append(state % self.height)\n",
        "    return tuple(reversed(out))\n",
        "\n",
        "  def set_start(self, start):\n",
        "    self.maze[start] = 10\n",
        "    self.start = start\n",
        "    self.state = start\n",
        "\n",
        "  def set_goal(self,goal):\n",
        "    self.maze[goal] = 12\n",
        "    self.goal = goal\n",
        "\n",
        "  def reset(self):\n",
        "    self.state = self.encode_state(self.start[0], self.start[1])\n",
        "    return self.state\n",
        "\n",
        "  def step(self, a):\n",
        "    #print(self.state)\n",
        "    transitions = self.R[self.state][a]\n",
        "    transitions = transitions[0]\n",
        "    prob, state, reward, done = transitions[0], transitions[1], transitions[2], transitions[3]\n",
        "    return prob, state, reward, done\n",
        "\n",
        "  def render(self, trafic = [], states = []):\n",
        "    out = self.maze.copy()\n",
        "    out[np.where(out == 0)] = 2\n",
        "    out[np.where(out == 1)] = 4\n",
        "    for i in range(len(trafic)):\n",
        "      out[self.decode_state(trafic[i])] = 20\n",
        "    for i in range(len(states)):\n",
        "      out[self.decode_state(states[i])] = 5\n",
        "    #print(\"decoding state: \", self.state)\n",
        "    car_row, car_col = self.decode_state(self.state)\n",
        "    #print(\"car_row: \", car_row, \"car_col: \", car_col)\n",
        "    out[car_row][car_col] = 7\n",
        "    img = out\n",
        "    return img\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRHyHBJO48uy",
        "colab_type": "code",
        "outputId": "181c1b37-85ab-4d51-d4bb-e82ce4051dd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "block_width = 50\n",
        "block_height = 50\n",
        "blocks = 6\n",
        "start_car = ((block_height-2),1)\n",
        "destination = (1, block_width-2)\n",
        "\n",
        "environment_params = {'block_width': block_width, 'block_height': block_height, 'blocks' : blocks, 'obstacle_width': block_width - 2, 'obstacle_height': 3, 'start_car': start_car, 'destination': destination}\n",
        "env = driver(**environment_params)\n",
        "\n",
        "print(env.maze)\n",
        "print(\"Action Space '{}'\".format(env.action_space))\n",
        "print(\"State Space '{}'\".format(env.observation_space))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_states 2500\n",
            "[[ 1  1  1 ...  1  1  1]\n",
            " [ 1  0  0 ...  0 12  1]\n",
            " [ 1  0  1 ...  1  0  1]\n",
            " ...\n",
            " [ 1  0  1 ...  1  0  1]\n",
            " [ 1 10  0 ...  0  0  1]\n",
            " [ 1  1  1 ...  1  1  1]]\n",
            "Action Space 'Discrete(4)'\n",
            "State Space 'Discrete(2500)'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYmLN9KkcRy_",
        "colab_type": "code",
        "outputId": "c07cad92-f290-412c-dbbf-8cee3a3c4c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "img = env.render()\n",
        "plt.imshow(img, cmap= 'viridis')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5a1d4b0128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/D+zc7UCyarKZAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBgiLWopb1AD",
        "colab_type": "code",
        "outputId": "34c40070-237b-4bac-fb71-cecacbeb951b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "if env.start == env.state:\n",
        "  print(\"we are in start position state:\", env.state)\n",
        "else:\n",
        "  print(\"state:\", env.state)\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(1,5, figsize = (15,15))\n",
        "transitions_val = []\n",
        "\n",
        "#we set a state where we are next to the goal\n",
        "print(\"\\n setting state to state next to goal\")\n",
        "state = (destination[0] + 1, destination[1])\n",
        "state = env.encode_state(state[0],state[1])\n",
        "env.state = state\n",
        "if env.start == env.state:\n",
        "  print(\"we are in start position state:\", env.state)\n",
        "else:\n",
        "  print(\"state:\", env.state)\n",
        "#print(\"destination:\",env.goal)\n",
        "#print(env.R[env.state])\n",
        "transitions_val.append(env.R[env.state])\n",
        "#print(\"transitions: \", env.R[env.state][1])\n",
        "img = env.render()\n",
        "axs[0].imshow(img)\n",
        "axs[0].set_title(\"State next to the goal\")\n",
        "\n",
        "#we set a state at a intersection to check \n",
        "print(\"\\n setting state to state at intersection\")\n",
        "intersect = block_width / blocks\n",
        "intersect = int(intersect)\n",
        "state = env.encode_state(intersect,intersect)\n",
        "env.state = state\n",
        "if env.start == env.state:\n",
        "  print(\"we are in start position state:\", env.state)\n",
        "else:\n",
        "  print(\"state:\", env.state)\n",
        "transitions_val.append(env.R[env.state])\n",
        "#print(\"destination:\",env.goal)\n",
        "#print(env.R[36])\n",
        "img = env.render()\n",
        "axs[1].imshow(img)\n",
        "axs[1].set_title(\"State at intersection\")\n",
        "\n",
        "\n",
        "#we set a state where we are chrashed in a building only acceptable action is getting out of the wall (West in this case)\n",
        "#print(\"\\n setting car crash, nooo\")\n",
        "state = env.encode_state(2,9)\n",
        "env.state = state\n",
        "if env.start == env.state:\n",
        "  print(\"we are in start position state:\", env.state)\n",
        "else:\n",
        "  print(\"state:\", env.state)\n",
        "#print(\"destination:\",env.goal)\n",
        "#print(env.R[29])\n",
        "transitions_val.append(env.R[env.state])\n",
        "img = env.render()\n",
        "axs[2].imshow(img)\n",
        "axs[2].set_title(\"State when crashed\")\n",
        "\n",
        "print(\"\\n reset environment state:\",env.reset())\n",
        "#print(\"state: \", env.state)\n",
        "img = env.render()\n",
        "transitions_val.append(env.R[env.state])\n",
        "axs[3].imshow(img)\n",
        "axs[3].set_title(\"Environment reset\")\n",
        "\n",
        "print(np.asarray(transitions_val))\n",
        "\n",
        "trafics = [(1,17),(1,18),(1,18),(1,19),(1,20),(1,21),(1,22),(1,22),(1,23),(1,24),(1,25),(1,25),(2,24),(3,24),(4,24),(5,24)]\n",
        "print(trafics[0])\n",
        "trafics_encoded = []\n",
        "for i, value in enumerate(trafics):\n",
        "  trafics_encoded.append(env.encode_state(value[0],value[1]))\n",
        "img = env.render(trafics_encoded)\n",
        "axs[4].imshow(img)\n",
        "axs[4].set_title(\"Environment with trafic\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state: 2401\n",
            "\n",
            " setting state to state next to goal\n",
            "state: 148\n",
            "\n",
            " setting state to state at intersection\n",
            "state: 408\n",
            "state: 109\n",
            "\n",
            " reset environment state: 2401\n",
            "[{0: [[1, 98, 100, True]], 1: [[1, 198, -1, False]], 2: [[1, 149, -50, False]], 3: [[1, 147, -50, False]]}\n",
            " {0: [[1, 358, -1, False]], 1: [[1, 458, -1, False]], 2: [[1, 409, -1, False]], 3: [[1, 407, -1, False]]}\n",
            " {0: [[1, 59, -1, False]], 1: [[1, 159, -50, False]], 2: [[1, 110, -50, False]], 3: [[1, 108, -1, False]]}\n",
            " {0: [[1, 2351, -1, False]], 1: [[1, 2451, -50, False]], 2: [[1, 2402, -1, False]], 3: [[1, 2400, -50, False]]}]\n",
            "(1, 17)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Environment with trafic')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAC/CAYAAAB6zqS6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paPc0_KPWB70",
        "colab_type": "code",
        "outputId": "465225fa-78bc-4b1a-f134-a06b8ac9160f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "import copy\n",
        "############### create traffic 😤😤😤 #####################\n",
        "traffics = []\n",
        "def create_traffic(begin_row, end_row, begin_col, end_col):\n",
        "  for i in range(begin_row, end_row):\n",
        "    for j in range(begin_col, end_col):\n",
        "      if env.maze[i,j] == 0:\n",
        "        state = env.encode_state(i,j)\n",
        "        traffics.append(state)\n",
        "\n",
        "trafic_R = copy.deepcopy(env.R)\n",
        "def create_trafic_R(jam_list,reward_traffic):\n",
        "  for i, value in enumerate(jam_list):\n",
        "    traf = np.copy(value)\n",
        "    #print(\"trafic_R[value]\",trafic_R[value],\"\\n env.R\", env.R[value])\n",
        "    for i in range(4):\n",
        "      if trafic_R[value][i][0][2] == -1:\n",
        "        trafic_R[value][i][0][2] = reward_traffic\n",
        "    #print(\"traffic_R[value]\", trafic_R[value])\n",
        "  return trafic_R\n",
        "\n",
        "create_traffic(begin_row = 8, end_row = 20, begin_col = 8, end_col = 50)\n",
        "create_traffic(begin_row = 32, end_row = 41, begin_col = 0, end_col = 41)\n",
        "#create R for traffic\n",
        "trafic_R = create_trafic_R(traffics, reward_traffic = -11)\n",
        "env.trafic_R = trafic_R\n",
        "# set trafic R matrix\n",
        "img = env.render(traffics)\n",
        "plt.imshow(img)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5a1ca8b6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKGGq5NsLZlA",
        "colab_type": "code",
        "outputId": "a2781843-9cf6-4508-9ea8-8f81a244a941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        }
      },
      "source": [
        "############### training #############\n",
        "import time\n",
        "start_time = time.time()\n",
        "from IPython.display import clear_output\n",
        "import random\n",
        "\n",
        "print( 20 * \"#\" + \" Attention resetting Q matrix \" + 20 * \"#\")\n",
        "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "print(\"Q matrix shape\\n\",Q.shape)\n",
        "\n",
        "alpha = 0.1\n",
        "gamma = 0.6\n",
        "epsilon = 0.5\n",
        "\n",
        "epochs = []\n",
        "penalties = []\n",
        "average_rewards = []\n",
        "steps = []\n",
        "\n",
        "print(\"start state: \", env.start, \"destination: \", env.goal)\n",
        "\n",
        "for i in range(1,10000): #change this 5 to 10001\n",
        "  state = env.reset()\n",
        "  #print(\"state\", state)\n",
        "  epochs, penalties, reward = 0,0,0\n",
        "  step_until_goal = 0\n",
        "  total_reward = 0\n",
        "  done = False\n",
        "  \n",
        "  while not done:\n",
        "    if random.uniform(0,1) < epsilon: \n",
        "      action = env.action_space.sample() # explore 🧐\n",
        "    else:\n",
        "      action = np.argmax(Q[state]) # exploit 😈\n",
        "\n",
        "    #print(\"action\", action, \"state\", env.state)\n",
        "    Prob, Next_state, Reward, Done = env.step(action)\n",
        "    #print(\"prob:\", Prob, \"Next_state: \", Next_state, \"reward: \", Reward, \"done\", Done)\n",
        "    #print(\"We have taken action '{}' and this resulted in state '{}' with a reward '{}'\".format(action, Next_state, Reward))\n",
        "\n",
        "    old_value = Q[state,action]\n",
        "    next_max = np.max(Q[Next_state])\n",
        "\n",
        "    new_value = (1 - alpha)*old_value + alpha*(Reward + gamma + next_max)\n",
        "    Q[state, action] = new_value\n",
        "    \n",
        "    if Reward == -10:\n",
        "      penalties += 1\n",
        "    total_reward += Reward\n",
        "    state = Next_state\n",
        "    env.state = state\n",
        "    epochs += 1\n",
        "    done = Done\n",
        "    step_until_goal += 1\n",
        "  \n",
        "  \n",
        "  if i % 500 == 0:\n",
        "    print(\"Reward until destination: \", total_reward/epochs, \"steps until goal\", step_until_goal)\n",
        "    average_rewards.append(total_reward/epochs)\n",
        "    steps.append(step_until_goal)\n",
        "  if i % 1000 == 0:\n",
        "    print(20 * \"#\" + \" We are Q learning rn \" + 20 * \"#\")\n",
        "\n",
        "print(20 * \"#\" + \" We Finished Q learning \" + 20 * \"#\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#################### Attention resetting Q matrix ####################\n",
            "Q matrix shape\n",
            " (2500, 4)\n",
            "start state:  (48, 1) destination:  (1, 48)\n",
            "Reward until destination:  -13.519553072625698 steps until goal 716\n",
            "Reward until destination:  -15.527472527472527 steps until goal 273\n",
            "#################### We are Q learning rn ####################\n",
            "Reward until destination:  -11.949771689497718 steps until goal 219\n",
            "Reward until destination:  -14.730627306273062 steps until goal 271\n",
            "#################### We are Q learning rn ####################\n",
            "Reward until destination:  -15.79496402877698 steps until goal 278\n",
            "Reward until destination:  -13.143410852713178 steps until goal 258\n",
            "#################### We are Q learning rn ####################\n",
            "Reward until destination:  -15.047826086956523 steps until goal 230\n",
            "Reward until destination:  -14.289285714285715 steps until goal 280\n",
            "#################### We are Q learning rn ####################\n",
            "Reward until destination:  -14.486792452830189 steps until goal 265\n",
            "Reward until destination:  -13.902027027027026 steps until goal 296\n",
            "#################### We are Q learning rn ####################\n",
            "Reward until destination:  -12.261061946902656 steps until goal 226\n",
            "Reward until destination:  -14.305825242718447 steps until goal 206\n",
            "#################### We are Q learning rn ####################\n",
            "Reward until destination:  -13.462962962962964 steps until goal 216\n",
            "Reward until destination:  -14.436090225563909 steps until goal 266\n",
            "#################### We are Q learning rn ####################\n",
            "Reward until destination:  -14.094650205761317 steps until goal 243\n",
            "Reward until destination:  -11.719047619047618 steps until goal 210\n",
            "#################### We are Q learning rn ####################\n",
            "Reward until destination:  -13.236607142857142 steps until goal 224\n",
            "Reward until destination:  -15.30722891566265 steps until goal 332\n",
            "#################### We are Q learning rn ####################\n",
            "Reward until destination:  -16.226148409893995 steps until goal 283\n",
            "#################### We Finished Q learning ####################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLjQYCfU2TVG",
        "colab_type": "code",
        "outputId": "bf48ef6a-231d-447f-e822-a859931f6f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "\"\"\"Evaluate agent's performance after Q-learning\"\"\"\n",
        "total_epochs, total_penalties = 0, 0\n",
        "episodes = 1\n",
        "frames = []\n",
        "states_eval = []\n",
        "for _ in range(episodes):\n",
        "    state = env.reset()\n",
        "    epochs, penalties, reward = 0, 0, 0\n",
        "    reward_until_goal = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = np.argmax(Q[state])\n",
        "        Prob, Next_state, Reward, Done = env.step(action)\n",
        "        if Reward == -10:\n",
        "          penalties += 1\n",
        "        state = Next_state\n",
        "        states_eval.append(state)\n",
        "        env.state = Next_state\n",
        "        done = Done\n",
        "        epochs += 1\n",
        "        reward += Reward\n",
        "        frames.append({'frame': env.render(states_eval), 'state': state, 'action': action, 'reward': reward})\n",
        "    reward_until_goal += (reward/epochs)\n",
        "    print(\"reached goal\")\n",
        "    total_epochs += epochs\n",
        "    total_penalties += penalties\n",
        "\n",
        "print(\"average reward until goal: \", reward_until_goal/episodes)\n",
        "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
        "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reached goal\n",
            "average reward until goal:  0.07446808510638298\n",
            "Average timesteps per episode: 94.0\n",
            "Average penalties per episode: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLGJH1AsD9fK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def print_frames(frames):\n",
        "  steps = 0\n",
        "  for i, frame in enumerate(frames):\n",
        "    if i % 6 == 0:\n",
        "      clear_output(wait = True)\n",
        "      print(f\"Timestep: {i + 1}\")\n",
        "      print(f\"State: {frame['state']}\")\n",
        "      print(f\"Action: {frame['action']}\")\n",
        "      print(f\"Reward: {frame['reward']}\")\n",
        "      plt.imshow(frame['frame'])\n",
        "      plt.show()\n",
        "      sleep(1)\n",
        "    steps += 1\n",
        "    if env.decode_state(frame['state']) == env.goal:\n",
        "      steps +=1\n",
        "      print(\"we reached our goal\")\n",
        "      print(f\"State: {frame['state']}\")\n",
        "      print(f\"Action: {frame['action']}\")\n",
        "      print(f\"Reward: {frame['reward']}\")\n",
        "      print(f\"With: {steps} steps\")\n",
        "      plt.imshow(frame['frame'])\n",
        "      plt.show()\n",
        "      sleep(1)\n",
        "\n",
        "    \n",
        "#print_frames(frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGtPkqLLakWQ",
        "colab_type": "code",
        "outputId": "fe29af4d-4a2a-42a7-9b98-16fcb0496fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        }
      },
      "source": [
        "################## train with traffic ##################\n",
        "\n",
        "alpha = 0.1\n",
        "gamma = 0.8\n",
        "epsilon = 0.5\n",
        "\n",
        "epochs = []\n",
        "penalties = []\n",
        "average_rewards = []\n",
        "steps = []\n",
        "Traffic = True\n",
        "env.trafic_R = trafic_R\n",
        "print(\"start state: \", env.start, \"destination: \", env.goal)\n",
        "for i in range(1,10000): #change this 5 to 10001\n",
        "  if Traffic == True:\n",
        "    env.R = env.trafic_R\n",
        "  state = env.reset()\n",
        "  #print(\"state\", state)\n",
        "  epochs, penalties, reward = 0,0,0\n",
        "  step_until_goal = 0\n",
        "  total_reward = 0\n",
        "  done = False\n",
        "  \n",
        "  while not done:\n",
        "    if random.uniform(0,1) < epsilon: \n",
        "      action = env.action_space.sample() # explore 🧐\n",
        "    else:\n",
        "      action = np.argmax(Q[state]) # exploit 😈\n",
        "\n",
        "    #print(\"action\", action, \"state\", env.state)\n",
        "    Prob, Next_state, Reward, Done = env.step(action)\n",
        "    #print(\"prob:\", Prob, \"Next_state: \", Next_state, \"reward: \", Reward, \"done\", Done)\n",
        "    #print(\"We have taken action '{}' and this resulted in state '{}' with a reward '{}'\".format(action, Next_state, Reward))\n",
        "\n",
        "    old_value = Q[state,action]\n",
        "    next_max = np.max(Q[Next_state])\n",
        "\n",
        "    #if state in traffics:\n",
        "      #print(\"We are stuck in a trafic jam please help\")\n",
        "    #  Reward = -6\n",
        "\n",
        "    new_value = (1 - alpha)*old_value + alpha*(Reward + gamma + next_max)\n",
        "    Q[state, action] = new_value\n",
        "    \n",
        "    if Reward == -10:\n",
        "      penalties += 1\n",
        "    total_reward += Reward\n",
        "    state = Next_state\n",
        "    env.state = state\n",
        "    epochs += 1\n",
        "    done = Done\n",
        "    step_until_goal += 1\n",
        "  \n",
        "  \n",
        "  if i % 250 == 0:\n",
        "    print(\"Reward until destination: \", total_reward/epochs, \"steps until goal\", step_until_goal)\n",
        "    average_rewards.append(total_reward/epochs)\n",
        "    steps.append(step_until_goal)\n",
        "  if i % 1000 == 0:\n",
        "    print(20 * \"#\" + \" We Q learning rn \" + 20 * \"#\")\n",
        "\n",
        "print(20 * \"#\" + \" We Finished Q learning \" + 20 * \"#\")\n",
        "average_steps = np.sum(steps)/len(steps)\n",
        "print(\"average steps\",average_steps)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start state:  (48, 1) destination:  (1, 48)\n",
            "Reward until destination:  -15.609098567818029 steps until goal 3561\n",
            "Reward until destination:  -14.351194786386676 steps until goal 1381\n",
            "Reward until destination:  -16.915673693858846 steps until goal 1091\n",
            "Reward until destination:  -15.232558139534884 steps until goal 645\n",
            "#################### We Q learning rn ####################\n",
            "Reward until destination:  -16.46474358974359 steps until goal 624\n",
            "Reward until destination:  -15.006535947712418 steps until goal 612\n",
            "Reward until destination:  -15.597682119205299 steps until goal 604\n",
            "Reward until destination:  -15.52280701754386 steps until goal 570\n",
            "#################### We Q learning rn ####################\n",
            "Reward until destination:  -17.020676691729324 steps until goal 532\n",
            "Reward until destination:  -13.970338983050848 steps until goal 472\n",
            "Reward until destination:  -13.195652173913043 steps until goal 506\n",
            "Reward until destination:  -14.886973180076629 steps until goal 522\n",
            "#################### We Q learning rn ####################\n",
            "Reward until destination:  -14.819502074688797 steps until goal 482\n",
            "Reward until destination:  -17.838541666666668 steps until goal 576\n",
            "Reward until destination:  -15.01830282861897 steps until goal 601\n",
            "Reward until destination:  -14.061111111111112 steps until goal 540\n",
            "#################### We Q learning rn ####################\n",
            "Reward until destination:  -16.672619047619047 steps until goal 672\n",
            "Reward until destination:  -14.341417910447761 steps until goal 536\n",
            "Reward until destination:  -14.708674304418984 steps until goal 611\n",
            "Reward until destination:  -14.380794701986755 steps until goal 604\n",
            "#################### We Q learning rn ####################\n",
            "Reward until destination:  -15.553480475382003 steps until goal 589\n",
            "Reward until destination:  -15.18095238095238 steps until goal 525\n",
            "Reward until destination:  -14.812 steps until goal 500\n",
            "Reward until destination:  -14.44253859348199 steps until goal 583\n",
            "#################### We Q learning rn ####################\n",
            "Reward until destination:  -16.00841750841751 steps until goal 594\n",
            "Reward until destination:  -11.548076923076923 steps until goal 520\n",
            "Reward until destination:  -17.07155322862129 steps until goal 573\n",
            "Reward until destination:  -14.89864864864865 steps until goal 444\n",
            "#################### We Q learning rn ####################\n",
            "Reward until destination:  -17.112396694214876 steps until goal 605\n",
            "Reward until destination:  -17.243523316062177 steps until goal 579\n",
            "Reward until destination:  -13.244094488188976 steps until goal 508\n",
            "Reward until destination:  -13.444672131147541 steps until goal 488\n",
            "#################### We Q learning rn ####################\n",
            "Reward until destination:  -14.605555555555556 steps until goal 540\n",
            "Reward until destination:  -16.366459627329192 steps until goal 644\n",
            "Reward until destination:  -15.856152512998268 steps until goal 577\n",
            "Reward until destination:  -14.821969696969697 steps until goal 528\n",
            "#################### We Q learning rn ####################\n",
            "Reward until destination:  -14.090909090909092 steps until goal 550\n",
            "Reward until destination:  -13.290874524714829 steps until goal 526\n",
            "Reward until destination:  -13.823636363636364 steps until goal 550\n",
            "#################### We Finished Q learning ####################\n",
            "average steps 670.8974358974359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYS_awtF2Tja",
        "colab_type": "code",
        "outputId": "482fba6c-32b7-490e-9502-f2f84067ec21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#### evaluate with traffic ######\n",
        "total_epochs, total_penalties = 0, 0\n",
        "episodes = 1\n",
        "frames = []\n",
        "for _ in range(episodes):\n",
        "    state = env.reset()\n",
        "    epochs, penalties, reward = 0, 0, 0\n",
        "    reward_until_goal = 0\n",
        "    done = False\n",
        "    states_eval = []\n",
        "    while not done:\n",
        "        action = np.argmax(Q[state])\n",
        "        Prob, Next_state, Reward, Done = env.step(action)\n",
        "        if Reward == -10:\n",
        "          penalties += 1\n",
        "        state = Next_state\n",
        "        states_eval.append(state)\n",
        "        env.state = Next_state\n",
        "        done = Done\n",
        "        epochs += 1\n",
        "        reward += Reward\n",
        "        frames.append({'frame': env.render(traffics,states_eval), 'state': state, 'action': action, 'reward': reward})\n",
        "    reward_until_goal += (reward/epochs)\n",
        "    print(\"reached goal\")\n",
        "    total_epochs += epochs\n",
        "    total_penalties += penalties\n",
        "\n",
        "print(\"average reward until goal: \", reward_until_goal/episodes)\n",
        "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
        "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reached goal\n",
            "average reward until goal:  -0.4627659574468085\n",
            "Average timesteps per episode: 188.0\n",
            "Average penalties per episode: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rdCkJAWMcol",
        "colab_type": "code",
        "outputId": "da342cff-999c-4007-fc50-92d18619f177",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "source": [
        "print_frames(frames)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Timestep: 187\n",
            "State: 97\n",
            "Action: 2\n",
            "Reward: -187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "we reached our goal\n",
            "State: 98\n",
            "Action: 2\n",
            "Reward: -87\n",
            "With: 189 steps\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSEM4vPHM3-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}